{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac7483-552d-4314-9a25-13d761373ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-------------------------------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     train(\u001b[43mtrain_dataloader\u001b[49m, predictor, loss_fn, optimizer)\n\u001b[32m     39\u001b[39m     test(test_dataloader, predictor, loss_fn)\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDone!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 8\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, predictor, loss_fn, optimizer)\n",
    "    test(test_dataloader, predictor, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fb5401-b71e-440e-bfd0-4532a09564e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "############## First step: I want to get the data first.  ################\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "training_images = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "############## Second step: I want to feem them into dataloaders ################\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader= DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader= DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "############## Third step: I want to define a neural network.  ################\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=2, stride=1, padding=0) #(64, 10, 27, 27)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) #(64, 10, 13, 13)\n",
    "        self.flatten = nn.Flatten() #(64, 13*13*10)\n",
    "        self.fc1 = nn.Linear(13*13*10, 10) # I expect input of shape (64, 1, 28 28)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.fc1(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6705bf0-9e3c-405c-be56-7eab64b5b857",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "predictor = SimpleCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860740e4-706c-4973-87bf-a7c0c6464595",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(predictor.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a5016-4427-423f-9258-06c319d0c173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.299180  [   64/60000]\n",
      "loss: 2.183776  [ 6464/60000]\n",
      "loss: 2.027440  [12864/60000]\n",
      "loss: 1.962413  [19264/60000]\n",
      "loss: 1.746058  [25664/60000]\n",
      "loss: 1.681250  [32064/60000]\n",
      "loss: 1.580736  [38464/60000]\n",
      "loss: 1.465430  [44864/60000]\n",
      "loss: 1.425099  [51264/60000]\n",
      "loss: 1.316373  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 1.264604 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.283192  [   64/60000]\n",
      "loss: 1.279251  [ 6464/60000]\n",
      "loss: 1.039515  [12864/60000]\n",
      "loss: 1.215304  [19264/60000]\n",
      "loss: 1.007443  [25664/60000]\n",
      "loss: 1.026875  [32064/60000]\n",
      "loss: 1.020897  [38464/60000]\n",
      "loss: 0.939810  [44864/60000]\n",
      "loss: 0.992733  [51264/60000]\n",
      "loss: 0.933743  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.888148 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.872512  [   64/60000]\n",
      "loss: 0.947338  [ 6464/60000]\n",
      "loss: 0.690628  [12864/60000]\n",
      "loss: 0.962121  [19264/60000]\n",
      "loss: 0.820269  [25664/60000]\n",
      "loss: 0.831720  [32064/60000]\n",
      "loss: 0.852603  [38464/60000]\n",
      "loss: 0.779981  [44864/60000]\n",
      "loss: 0.855373  [51264/60000]\n",
      "loss: 0.803769  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.762859 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.714373  [   64/60000]\n",
      "loss: 0.826459  [ 6464/60000]\n",
      "loss: 0.560515  [12864/60000]\n",
      "loss: 0.857869  [19264/60000]\n",
      "loss: 0.747113  [25664/60000]\n",
      "loss: 0.749695  [32064/60000]\n",
      "loss: 0.777400  [38464/60000]\n",
      "loss: 0.714836  [44864/60000]\n",
      "loss: 0.792361  [51264/60000]\n",
      "loss: 0.737687  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.700713 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.631706  [   64/60000]\n",
      "loss: 0.761696  [ 6464/60000]\n",
      "loss: 0.495636  [12864/60000]\n",
      "loss: 0.798396  [19264/60000]\n",
      "loss: 0.703119  [25664/60000]\n",
      "loss: 0.701907  [32064/60000]\n",
      "loss: 0.731236  [38464/60000]\n",
      "loss: 0.681368  [44864/60000]\n",
      "loss: 0.755293  [51264/60000]\n",
      "loss: 0.693874  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.661104 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.580030  [   64/60000]\n",
      "loss: 0.717674  [ 6464/60000]\n",
      "loss: 0.456393  [12864/60000]\n",
      "loss: 0.757499  [19264/60000]\n",
      "loss: 0.670712  [25664/60000]\n",
      "loss: 0.668846  [32064/60000]\n",
      "loss: 0.697581  [38464/60000]\n",
      "loss: 0.661823  [44864/60000]\n",
      "loss: 0.730614  [51264/60000]\n",
      "loss: 0.660233  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.632274 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.544026  [   64/60000]\n",
      "loss: 0.683759  [ 6464/60000]\n",
      "loss: 0.429391  [12864/60000]\n",
      "loss: 0.726389  [19264/60000]\n",
      "loss: 0.644743  [25664/60000]\n",
      "loss: 0.643959  [32064/60000]\n",
      "loss: 0.670665  [38464/60000]\n",
      "loss: 0.649721  [44864/60000]\n",
      "loss: 0.713250  [51264/60000]\n",
      "loss: 0.632293  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.609766 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.517040  [   64/60000]\n",
      "loss: 0.655902  [ 6464/60000]\n",
      "loss: 0.409124  [12864/60000]\n",
      "loss: 0.701377  [19264/60000]\n",
      "loss: 0.623164  [25664/60000]\n",
      "loss: 0.624373  [32064/60000]\n",
      "loss: 0.648044  [38464/60000]\n",
      "loss: 0.642137  [44864/60000]\n",
      "loss: 0.700757  [51264/60000]\n",
      "loss: 0.608164  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.591480 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 8\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, predictor, loss_fn, optimizer)\n",
    "    test(test_dataloader, predictor, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS OF TEST 1: FASTER CONVERGENCE THAN SHALLOWNN BENCHMARK, BUT DID NOT HAVE GREATER ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a98fb1a-2e07-4333-85f6-a4b9838c0175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "############## First step: I want to get the data first.  ################\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "training_images = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "############## Second step: I want to feem them into dataloaders ################\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader= DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader= DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "############## Third step: I want to define a neural network.  ################\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=2, stride=1, padding=0) #(64, 10, 27, 27)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) #(64, 10, 13, 13)\n",
    "        self.flatten = nn.Flatten() #(64, 13*13*10)\n",
    "        self.fc1 = nn.Linear(13*13*10, 10) # I expect input of shape (64, 1, 28 28)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.fc1(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47fe0e6-1332-4983-9510-4f75b4c6edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "predictor = SimpleCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59ab0a-827d-49e6-969c-d7515abf98d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(predictor.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a672a99-bb92-45bc-ab67-5f3e6e9d6dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "linear(): input and weight.T shapes cannot be multiplied (64x2704 and 1690x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-------------------------------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     test(test_dataloader, predictor, loss_fn)\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDone!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(dataloader, model, loss_fn, optimizer)\u001b[39m\n\u001b[32m      6\u001b[39m X, y = X.to(device), y.to(device)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Compute prediction error\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m loss = loss_fn(pred, y)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mSimpleCNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     47\u001b[39m x = \u001b[38;5;28mself\u001b[39m.maxpool(x)\n\u001b[32m     48\u001b[39m x = \u001b[38;5;28mself\u001b[39m.flatten(x)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: linear(): input and weight.T shapes cannot be multiplied (64x2704 and 1690x10)"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 8\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, predictor, loss_fn, optimizer)\n",
    "    test(test_dataloader, predictor, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de864a9c-c03f-46c4-9fe8-00baa0c3dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "############## First step: I want to get the data first.  ################\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "training_images = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "############## Second step: I want to feem them into dataloaders ################\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader= DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader= DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "############## Third step: I want to define a neural network.  ################\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=2, stride=1, padding=0) #(64, 10, 27, 27)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) #(64, 16, 13, 13)\n",
    "        self.flatten = nn.Flatten() #(64, 13*13*16)\n",
    "        self.fc1 = nn.Linear(13*13*16, 10) # I expect input of shape (64, 1, 28 28)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.fc1(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3a7bcc-bc0d-4be8-be2d-1e9e3dfa6262",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "predictor = SimpleCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5a8dc1-7ade-499f-b8d1-70bf1a23d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(predictor.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe3f47-f0d1-487c-b83a-7c885655ea02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.332322  [   64/60000]\n",
      "loss: 2.109899  [ 6464/60000]\n",
      "loss: 1.867699  [12864/60000]\n",
      "loss: 1.793984  [19264/60000]\n",
      "loss: 1.535518  [25664/60000]\n",
      "loss: 1.482808  [32064/60000]\n",
      "loss: 1.384373  [38464/60000]\n",
      "loss: 1.272338  [44864/60000]\n",
      "loss: 1.255532  [51264/60000]\n",
      "loss: 1.150297  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 1.111953 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.132678  [   64/60000]\n",
      "loss: 1.143087  [ 6464/60000]\n",
      "loss: 0.883549  [12864/60000]\n",
      "loss: 1.106613  [19264/60000]\n",
      "loss: 0.925733  [25664/60000]\n",
      "loss: 0.941186  [32064/60000]\n",
      "loss: 0.941024  [38464/60000]\n",
      "loss: 0.864993  [44864/60000]\n",
      "loss: 0.928262  [51264/60000]\n",
      "loss: 0.861324  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.830864 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.811736  [   64/60000]\n",
      "loss: 0.889764  [ 6464/60000]\n",
      "loss: 0.622840  [12864/60000]\n",
      "loss: 0.914287  [19264/60000]\n",
      "loss: 0.788891  [25664/60000]\n",
      "loss: 0.791702  [32064/60000]\n",
      "loss: 0.808945  [38464/60000]\n",
      "loss: 0.744143  [44864/60000]\n",
      "loss: 0.820310  [51264/60000]\n",
      "loss: 0.757862  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.730724 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.683734  [   64/60000]\n",
      "loss: 0.789061  [ 6464/60000]\n",
      "loss: 0.522650  [12864/60000]\n",
      "loss: 0.827231  [19264/60000]\n",
      "loss: 0.727738  [25664/60000]\n",
      "loss: 0.722933  [32064/60000]\n",
      "loss: 0.743201  [38464/60000]\n",
      "loss: 0.691828  [44864/60000]\n",
      "loss: 0.766046  [51264/60000]\n",
      "loss: 0.700394  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.676643 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.613178  [   64/60000]\n",
      "loss: 0.730213  [ 6464/60000]\n",
      "loss: 0.470457  [12864/60000]\n",
      "loss: 0.773348  [19264/60000]\n",
      "loss: 0.687733  [25664/60000]\n",
      "loss: 0.680527  [32064/60000]\n",
      "loss: 0.699981  [38464/60000]\n",
      "loss: 0.663979  [44864/60000]\n",
      "loss: 0.732360  [51264/60000]\n",
      "loss: 0.660132  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.640499 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.567180  [   64/60000]\n",
      "loss: 0.688342  [ 6464/60000]\n",
      "loss: 0.437683  [12864/60000]\n",
      "loss: 0.734402  [19264/60000]\n",
      "loss: 0.657163  [25664/60000]\n",
      "loss: 0.650608  [32064/60000]\n",
      "loss: 0.667474  [38464/60000]\n",
      "loss: 0.647581  [44864/60000]\n",
      "loss: 0.709479  [51264/60000]\n",
      "loss: 0.628501  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.613635 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.534064  [   64/60000]\n",
      "loss: 0.655507  [ 6464/60000]\n",
      "loss: 0.414478  [12864/60000]\n",
      "loss: 0.703995  [19264/60000]\n",
      "loss: 0.632337  [25664/60000]\n",
      "loss: 0.628037  [32064/60000]\n",
      "loss: 0.641285  [38464/60000]\n",
      "loss: 0.637546  [44864/60000]\n",
      "loss: 0.693348  [51264/60000]\n",
      "loss: 0.602206  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.592503 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.508635  [   64/60000]\n",
      "loss: 0.628534  [ 6464/60000]\n",
      "loss: 0.396692  [12864/60000]\n",
      "loss: 0.679258  [19264/60000]\n",
      "loss: 0.611627  [25664/60000]\n",
      "loss: 0.610342  [32064/60000]\n",
      "loss: 0.619367  [38464/60000]\n",
      "loss: 0.631410  [44864/60000]\n",
      "loss: 0.681798  [51264/60000]\n",
      "loss: 0.579791  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.575302 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 8\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, predictor, loss_fn, optimizer)\n",
    "    test(test_dataloader, predictor, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c2ef86-a148-48a5-a4da-b2279c54fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "############## First step: I want to get the data first.  ################\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "training_images = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "############## Second step: I want to feem them into dataloaders ################\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader= DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader= DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "############## Third step: I want to define a neural network.  ################\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=4, stride=1, padding=0) #(64, 10, 25, 25) (28-4)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) #(64, 10, 12, 12)\n",
    "        self.flatten = nn.Flatten() #(64, 12*12*10)\n",
    "        self.fc1 = nn.Linear(12*12*10, 10) # I expect input of shape (64, 1, 28 28)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.fc1(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e0210-265e-4c51-a1a1-60279ef665df",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "predictor = SimpleCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a511ec-9494-4ef8-9272-33839a160992",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(predictor.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85be14-d41f-4274-a957-0f2311b13a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "linear(): input and weight.T shapes cannot be multiplied (64x2304 and 1440x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-------------------------------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     test(test_dataloader, predictor, loss_fn)\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDone!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(dataloader, model, loss_fn, optimizer)\u001b[39m\n\u001b[32m      6\u001b[39m X, y = X.to(device), y.to(device)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Compute prediction error\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m loss = loss_fn(pred, y)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mSimpleCNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     47\u001b[39m x = \u001b[38;5;28mself\u001b[39m.maxpool(x)\n\u001b[32m     48\u001b[39m x = \u001b[38;5;28mself\u001b[39m.flatten(x)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: linear(): input and weight.T shapes cannot be multiplied (64x2304 and 1440x10)"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 8\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, predictor, loss_fn, optimizer)\n",
    "    test(test_dataloader, predictor, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c6b16b-27fd-4b0a-915c-0318967e75ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "############## First step: I want to get the data first.  ################\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "training_images = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "############## Second step: I want to feem them into dataloaders ################\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader= DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader= DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "############## Third step: I want to define a neural network.  ################\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=4, stride=1, padding=0) #(64, 10, 25, 25) (28-4)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) #(64, 10, 12, 12)\n",
    "        self.flatten = nn.Flatten() #(64, 12*12*10)\n",
    "        self.fc1 = nn.Linear(12*12*10, 10) # I expect input of shape (64, 1, 28 28)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.fc1(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e960b1-74b8-4498-9e04-4a50cf899032",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "predictor = SimpleCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c8235f-3a7f-4f01-8e94-5f8de16d86ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(predictor.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfc8d96-d73b-427f-b415-42840e176837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.334426  [   64/60000]\n",
      "loss: 2.190278  [ 6464/60000]\n",
      "loss: 1.981205  [12864/60000]\n",
      "loss: 1.883564  [19264/60000]\n",
      "loss: 1.633538  [25664/60000]\n",
      "loss: 1.519789  [32064/60000]\n",
      "loss: 1.410609  [38464/60000]\n",
      "loss: 1.261263  [44864/60000]\n",
      "loss: 1.264759  [51264/60000]\n",
      "loss: 1.107930  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 1.093746 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.144374  [   64/60000]\n",
      "loss: 1.138559  [ 6464/60000]\n",
      "loss: 0.874067  [12864/60000]\n",
      "loss: 1.057925  [19264/60000]\n",
      "loss: 0.874552  [25664/60000]\n",
      "loss: 0.906626  [32064/60000]\n",
      "loss: 0.914740  [38464/60000]\n",
      "loss: 0.819495  [44864/60000]\n",
      "loss: 0.893028  [51264/60000]\n",
      "loss: 0.854761  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.814697 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.795649  [   64/60000]\n",
      "loss: 0.893779  [ 6464/60000]\n",
      "loss: 0.613758  [12864/60000]\n",
      "loss: 0.888426  [19264/60000]\n",
      "loss: 0.748905  [25664/60000]\n",
      "loss: 0.774068  [32064/60000]\n",
      "loss: 0.798908  [38464/60000]\n",
      "loss: 0.710669  [44864/60000]\n",
      "loss: 0.786471  [51264/60000]\n",
      "loss: 0.777397  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.725543 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.667178  [   64/60000]\n",
      "loss: 0.797176  [ 6464/60000]\n",
      "loss: 0.521632  [12864/60000]\n",
      "loss: 0.815074  [19264/60000]\n",
      "loss: 0.696222  [25664/60000]\n",
      "loss: 0.716153  [32064/60000]\n",
      "loss: 0.744307  [38464/60000]\n",
      "loss: 0.669407  [44864/60000]\n",
      "loss: 0.736014  [51264/60000]\n",
      "loss: 0.731246  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.678311 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.598595  [   64/60000]\n",
      "loss: 0.738760  [ 6464/60000]\n",
      "loss: 0.473559  [12864/60000]\n",
      "loss: 0.768575  [19264/60000]\n",
      "loss: 0.661632  [25664/60000]\n",
      "loss: 0.681581  [32064/60000]\n",
      "loss: 0.707749  [38464/60000]\n",
      "loss: 0.648863  [44864/60000]\n",
      "loss: 0.706252  [51264/60000]\n",
      "loss: 0.695549  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.647002 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.554387  [   64/60000]\n",
      "loss: 0.696696  [ 6464/60000]\n",
      "loss: 0.442392  [12864/60000]\n",
      "loss: 0.734756  [19264/60000]\n",
      "loss: 0.635751  [25664/60000]\n",
      "loss: 0.657841  [32064/60000]\n",
      "loss: 0.678980  [38464/60000]\n",
      "loss: 0.637080  [44864/60000]\n",
      "loss: 0.687074  [51264/60000]\n",
      "loss: 0.665212  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.623872 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.523006  [   64/60000]\n",
      "loss: 0.664068  [ 6464/60000]\n",
      "loss: 0.419731  [12864/60000]\n",
      "loss: 0.708670  [19264/60000]\n",
      "loss: 0.615510  [25664/60000]\n",
      "loss: 0.640252  [32064/60000]\n",
      "loss: 0.654839  [38464/60000]\n",
      "loss: 0.629948  [44864/60000]\n",
      "loss: 0.674367  [51264/60000]\n",
      "loss: 0.638784  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.605738 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.499371  [   64/60000]\n",
      "loss: 0.638101  [ 6464/60000]\n",
      "loss: 0.402125  [12864/60000]\n",
      "loss: 0.687836  [19264/60000]\n",
      "loss: 0.599258  [25664/60000]\n",
      "loss: 0.626551  [32064/60000]\n",
      "loss: 0.634129  [38464/60000]\n",
      "loss: 0.625548  [44864/60000]\n",
      "loss: 0.665865  [51264/60000]\n",
      "loss: 0.615759  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.590962 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 8\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, predictor, loss_fn, optimizer)\n",
    "    test(test_dataloader, predictor, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d821b35f-6e80-4f35-9d72-1ea9489abe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "############## First step: I want to get the data first.  ################\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "training_images = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "############## Second step: I want to feem them into dataloaders ################\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader= DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader= DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "############## Third step: I want to define a neural network.  ################\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=2, stride=1, padding=0) #(64, 10, 27, 27)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) #(64, 10, 13, 13)\n",
    "        self.flatten = nn.Flatten() #(64, 13*13*10)\n",
    "        self.fc1 = nn.Linear(13*13*10, 10) # I expect input of shape (64, 1, 28 28)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.fc1(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688242a-c6c6-423d-83af-def12ff1884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "predictor = SimpleCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccc7ce5-eeaf-4476-aa08-a513e982544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(predictor.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d12137-341d-451d-a93f-f74aeabcbecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.364555  [   64/60000]\n",
      "loss: 2.243427  [ 6464/60000]\n",
      "loss: 2.096150  [12864/60000]\n",
      "loss: 2.050838  [19264/60000]\n",
      "loss: 1.869786  [25664/60000]\n",
      "loss: 1.810456  [32064/60000]\n",
      "loss: 1.716196  [38464/60000]\n",
      "loss: 1.588236  [44864/60000]\n",
      "loss: 1.532109  [51264/60000]\n",
      "loss: 1.420241  [57664/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-------------------------------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     test(test_dataloader, predictor, loss_fn)\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDone!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(dataloader, model, loss_fn, optimizer)\u001b[39m\n\u001b[32m      3\u001b[39m size = \u001b[38;5;28mlen\u001b[39m(dataloader.dataset)\n\u001b[32m      4\u001b[39m model.train()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Compute prediction error\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/utils/data/dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/utils/data/dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torchvision/datasets/mnist.py:146\u001b[39m, in \u001b[36mMNIST.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    143\u001b[39m img = _Image_fromarray(img.numpy(), mode=\u001b[33m\"\u001b[39m\u001b[33mL\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     img = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    149\u001b[39m     target = \u001b[38;5;28mself\u001b[39m.target_transform(target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torchvision/transforms/transforms.py:137\u001b[39m, in \u001b[36mToTensor.__call__\u001b[39m\u001b[34m(self, pic)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[32m    130\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m \u001b[33;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torchvision/transforms/functional.py:176\u001b[39m, in \u001b[36mto_tensor\u001b[39m\u001b[34m(pic)\u001b[39m\n\u001b[32m    174\u001b[39m img = img.permute((\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)).contiguous()\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch.ByteTensor):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdiv\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m255\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 8\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, predictor, loss_fn, optimizer)\n",
    "    test(test_dataloader, predictor, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedd055d-ccc6-49f3-9b24-ebff83e2e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "############## First step: I want to get the data first.  ################\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "training_images = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "############## Second step: I want to feem them into dataloaders ################\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader= DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader= DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "############## Third step: I want to define a neural network.  ################\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=2, stride=1, padding=0) #(64, 10, 27, 27)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) #(64, 10, 13, 13)\n",
    "        self.flatten = nn.Flatten() #(64, 13*13*10)\n",
    "        self.fc1 = nn.Linear(13*13*10, 10) # I expect input of shape (64, 1, 28 28)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.fc1(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ad75ba-a3ab-4846-911d-e216f33f6083",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "predictor = SimpleCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e78d80-aba9-4899-bea9-c4287f12b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(predictor.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d2f623-df2b-4596-9a5c-60d7173e7201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.307273  [   64/60000]\n",
      "loss: 0.776314  [ 6464/60000]\n",
      "loss: 0.417329  [12864/60000]\n",
      "loss: 0.639430  [19264/60000]\n",
      "loss: 0.524466  [25664/60000]\n",
      "loss: 0.543276  [32064/60000]\n",
      "loss: 0.473569  [38464/60000]\n",
      "loss: 0.664330  [44864/60000]\n",
      "loss: 0.648229  [51264/60000]\n",
      "loss: 0.466071  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.448551 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.337009  [   64/60000]\n",
      "loss: 0.485973  [ 6464/60000]\n",
      "loss: 0.273855  [12864/60000]\n",
      "loss: 0.477623  [19264/60000]\n",
      "loss: 0.430808  [25664/60000]\n",
      "loss: 0.477435  [32064/60000]\n",
      "loss: 0.368019  [38464/60000]\n",
      "loss: 0.614318  [44864/60000]\n",
      "loss: 0.594686  [51264/60000]\n",
      "loss: 0.419313  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.412028 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.290391  [   64/60000]\n",
      "loss: 0.456848  [ 6464/60000]\n",
      "loss: 0.247669  [12864/60000]\n",
      "loss: 0.444873  [19264/60000]\n",
      "loss: 0.393946  [25664/60000]\n",
      "loss: 0.457245  [32064/60000]\n",
      "loss: 0.323910  [38464/60000]\n",
      "loss: 0.570376  [44864/60000]\n",
      "loss: 0.557283  [51264/60000]\n",
      "loss: 0.394729  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.393209 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.268542  [   64/60000]\n",
      "loss: 0.441074  [ 6464/60000]\n",
      "loss: 0.234861  [12864/60000]\n",
      "loss: 0.428283  [19264/60000]\n",
      "loss: 0.372142  [25664/60000]\n",
      "loss: 0.443368  [32064/60000]\n",
      "loss: 0.301712  [38464/60000]\n",
      "loss: 0.538380  [44864/60000]\n",
      "loss: 0.527558  [51264/60000]\n",
      "loss: 0.380268  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.382382 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.255588  [   64/60000]\n",
      "loss: 0.429035  [ 6464/60000]\n",
      "loss: 0.226829  [12864/60000]\n",
      "loss: 0.417157  [19264/60000]\n",
      "loss: 0.357872  [25664/60000]\n",
      "loss: 0.432540  [32064/60000]\n",
      "loss: 0.288800  [38464/60000]\n",
      "loss: 0.514332  [44864/60000]\n",
      "loss: 0.502437  [51264/60000]\n",
      "loss: 0.371925  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.375341 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.246153  [   64/60000]\n",
      "loss: 0.418502  [ 6464/60000]\n",
      "loss: 0.221107  [12864/60000]\n",
      "loss: 0.409118  [19264/60000]\n",
      "loss: 0.345678  [25664/60000]\n",
      "loss: 0.423587  [32064/60000]\n",
      "loss: 0.280140  [38464/60000]\n",
      "loss: 0.494425  [44864/60000]\n",
      "loss: 0.481456  [51264/60000]\n",
      "loss: 0.367774  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.370006 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.237451  [   64/60000]\n",
      "loss: 0.409355  [ 6464/60000]\n",
      "loss: 0.216968  [12864/60000]\n",
      "loss: 0.402512  [19264/60000]\n",
      "loss: 0.334381  [25664/60000]\n",
      "loss: 0.415768  [32064/60000]\n",
      "loss: 0.273444  [38464/60000]\n",
      "loss: 0.478115  [44864/60000]\n",
      "loss: 0.464184  [51264/60000]\n",
      "loss: 0.365828  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.365785 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.229171  [   64/60000]\n",
      "loss: 0.401241  [ 6464/60000]\n",
      "loss: 0.213845  [12864/60000]\n",
      "loss: 0.395977  [19264/60000]\n",
      "loss: 0.324501  [25664/60000]\n",
      "loss: 0.407849  [32064/60000]\n",
      "loss: 0.267264  [38464/60000]\n",
      "loss: 0.464284  [44864/60000]\n",
      "loss: 0.448870  [51264/60000]\n",
      "loss: 0.364465  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.362153 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 8\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, predictor, loss_fn, optimizer)\n",
    "    test(test_dataloader, predictor, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478c67af-25f5-420c-967d-dc5c57f1bc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "############## First step: I want to get the data first.  ################\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "training_images = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "############## Second step: I want to feem them into dataloaders ################\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader= DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader= DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "############## Third step: I want to define a neural network.  ################\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=2, stride=1, padding=0) #(64, 10, 27, 27)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) #(64, 10, 13, 13)\n",
    "        self.flatten = nn.Flatten() #(64, 13*13*10)\n",
    "        self.fc1 = nn.Linear(13*13*10, 10) # I expect input of shape (64, 1, 28 28)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.fc1(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce51f45-5a15-4d8c-94ee-b1ff26cf23c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "predictor = SimpleCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adecda6d-cdc1-4574-be4c-2de30faeadd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(predictor.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9bd31-6f74-49b0-8df6-347ad43f320c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.298959  [   64/60000]\n",
      "loss: 0.781945  [ 6464/60000]\n",
      "loss: 0.423359  [12864/60000]\n",
      "loss: 0.666944  [19264/60000]\n",
      "loss: 0.550146  [25664/60000]\n",
      "loss: 0.554607  [32064/60000]\n",
      "loss: 0.463556  [38464/60000]\n",
      "loss: 0.678403  [44864/60000]\n",
      "loss: 0.666871  [51264/60000]\n",
      "loss: 0.450902  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.457057 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.354215  [   64/60000]\n",
      "loss: 0.484683  [ 6464/60000]\n",
      "loss: 0.289075  [12864/60000]\n",
      "loss: 0.490482  [19264/60000]\n",
      "loss: 0.417961  [25664/60000]\n",
      "loss: 0.491510  [32064/60000]\n",
      "loss: 0.352488  [38464/60000]\n",
      "loss: 0.595283  [44864/60000]\n",
      "loss: 0.579486  [51264/60000]\n",
      "loss: 0.413791  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.416837 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.293292  [   64/60000]\n",
      "loss: 0.447783  [ 6464/60000]\n",
      "loss: 0.265769  [12864/60000]\n",
      "loss: 0.455128  [19264/60000]\n",
      "loss: 0.375979  [25664/60000]\n",
      "loss: 0.476146  [32064/60000]\n",
      "loss: 0.308770  [38464/60000]\n",
      "loss: 0.543760  [44864/60000]\n",
      "loss: 0.525686  [51264/60000]\n",
      "loss: 0.387717  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.398051 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.266921  [   64/60000]\n",
      "loss: 0.430990  [ 6464/60000]\n",
      "loss: 0.253814  [12864/60000]\n",
      "loss: 0.436961  [19264/60000]\n",
      "loss: 0.360056  [25664/60000]\n",
      "loss: 0.465786  [32064/60000]\n",
      "loss: 0.286207  [38464/60000]\n",
      "loss: 0.514730  [44864/60000]\n",
      "loss: 0.491062  [51264/60000]\n",
      "loss: 0.367835  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.387155 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.250378  [   64/60000]\n",
      "loss: 0.420207  [ 6464/60000]\n",
      "loss: 0.245103  [12864/60000]\n",
      "loss: 0.423447  [19264/60000]\n",
      "loss: 0.355268  [25664/60000]\n",
      "loss: 0.455916  [32064/60000]\n",
      "loss: 0.272290  [38464/60000]\n",
      "loss: 0.496679  [44864/60000]\n",
      "loss: 0.464621  [51264/60000]\n",
      "loss: 0.352948  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.379623 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.237018  [   64/60000]\n",
      "loss: 0.411151  [ 6464/60000]\n",
      "loss: 0.237471  [12864/60000]\n",
      "loss: 0.410646  [19264/60000]\n",
      "loss: 0.353919  [25664/60000]\n",
      "loss: 0.446232  [32064/60000]\n",
      "loss: 0.262354  [38464/60000]\n",
      "loss: 0.483824  [44864/60000]\n",
      "loss: 0.442390  [51264/60000]\n",
      "loss: 0.341961  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.373736 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.225327  [   64/60000]\n",
      "loss: 0.402294  [ 6464/60000]\n",
      "loss: 0.230689  [12864/60000]\n",
      "loss: 0.398655  [19264/60000]\n",
      "loss: 0.352830  [25664/60000]\n",
      "loss: 0.436433  [32064/60000]\n",
      "loss: 0.254362  [38464/60000]\n",
      "loss: 0.473960  [44864/60000]\n",
      "loss: 0.422830  [51264/60000]\n",
      "loss: 0.333282  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.368861 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.214476  [   64/60000]\n",
      "loss: 0.393074  [ 6464/60000]\n",
      "loss: 0.224734  [12864/60000]\n",
      "loss: 0.387363  [19264/60000]\n",
      "loss: 0.350993  [25664/60000]\n",
      "loss: 0.427030  [32064/60000]\n",
      "loss: 0.247505  [38464/60000]\n",
      "loss: 0.465722  [44864/60000]\n",
      "loss: 0.405628  [51264/60000]\n",
      "loss: 0.325455  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.364695 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 8\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, predictor, loss_fn, optimizer)\n",
    "    test(test_dataloader, predictor, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c91ec17-93a1-4021-98dc-e08ef7d40132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "############## First step: I want to get the data first.  ################\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "training_images = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "############## Second step: I want to feem them into dataloaders ################\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader= DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader= DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "############## Third step: I want to define a neural network.  ################\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=2, stride=1, padding=0) #(64, 10, 27, 27)\n",
    "        self.bn = nn.BatchNorm2d(1)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) #(64, 10, 13, 13)\n",
    "        self.flatten = nn.Flatten() #(64, 13*13*10)\n",
    "        self.fc1 = nn.Linear(13*13*10, 10) # I expect input of shape (64, 1, 28 28)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.fc1(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058b0d9d-5fea-4b39-b46d-0d4362b4ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "predictor = SimpleCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2415365-a725-4bfa-b742-204331ab940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(predictor.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b1fa1-437e-463f-99ad-c0b994d7e389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 10 elements not 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-------------------------------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     test(test_dataloader, predictor, loss_fn)\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDone!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(dataloader, model, loss_fn, optimizer)\u001b[39m\n\u001b[32m      6\u001b[39m X, y = X.to(device), y.to(device)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Compute prediction error\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m loss = loss_fn(pred, y)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mSimpleCNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     47\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.conv(x)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.maxpool(x)\n\u001b[32m     50\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.flatten(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193\u001b[39m, in \u001b[36m_BatchNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    186\u001b[39m     bn_training = (\u001b[38;5;28mself\u001b[39m.running_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.running_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    188\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[33;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[33;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_mean\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/functional.py:2817\u001b[39m, in \u001b[36mbatch_norm\u001b[39m\u001b[34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[39m\n\u001b[32m   2814\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[32m   2815\u001b[39m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m.size())\n\u001b[32m-> \u001b[39m\u001b[32m2817\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2818\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2819\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2820\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2821\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2822\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2823\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2824\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2825\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2827\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: running_mean should contain 10 elements not 1"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 8\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, predictor, loss_fn, optimizer)\n",
    "    test(test_dataloader, predictor, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c8826e-77ce-4fb0-9af9-98effedb8e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "############## First step: I want to get the data first.  ################\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "training_images = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "############## Second step: I want to feem them into dataloaders ################\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader= DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader= DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "############## Third step: I want to define a neural network.  ################\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=2, stride=1, padding=0) #(64, 10, 27, 27)\n",
    "        self.bn = nn.BatchNorm2d(10)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) #(64, 10, 13, 13)\n",
    "        self.flatten = nn.Flatten() #(64, 13*13*10)\n",
    "        self.fc1 = nn.Linear(13*13*10, 10) # I expect input of shape (64, 1, 28 28)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.fc1(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b778f2-f697-476c-8c9e-b165d33363a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "predictor = SimpleCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c602d1-73b3-4afa-8748-5c2fd1ec4a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(predictor.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2e59e2-5a2c-4705-8d94-87ccb3d598b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.279783  [   64/60000]\n",
      "loss: 0.489716  [ 6464/60000]\n",
      "loss: 0.347683  [12864/60000]\n",
      "loss: 0.440587  [19264/60000]\n",
      "loss: 0.372968  [25664/60000]\n",
      "loss: 0.479028  [32064/60000]\n",
      "loss: 0.319044  [38464/60000]\n",
      "loss: 0.571191  [44864/60000]\n",
      "loss: 0.395446  [51264/60000]\n",
      "loss: 0.459320  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.407220 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.225344  [   64/60000]\n",
      "loss: 0.433935  [ 6464/60000]\n",
      "loss: 0.294492  [12864/60000]\n",
      "loss: 0.323992  [19264/60000]\n",
      "loss: 0.346038  [25664/60000]\n",
      "loss: 0.430021  [32064/60000]\n",
      "loss: 0.223236  [38464/60000]\n",
      "loss: 0.540384  [44864/60000]\n",
      "loss: 0.311638  [51264/60000]\n",
      "loss: 0.400953  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.381542 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.188903  [   64/60000]\n",
      "loss: 0.397449  [ 6464/60000]\n",
      "loss: 0.273676  [12864/60000]\n",
      "loss: 0.301414  [19264/60000]\n",
      "loss: 0.312838  [25664/60000]\n",
      "loss: 0.406580  [32064/60000]\n",
      "loss: 0.200504  [38464/60000]\n",
      "loss: 0.519941  [44864/60000]\n",
      "loss: 0.293209  [51264/60000]\n",
      "loss: 0.351238  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.368273 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.174045  [   64/60000]\n",
      "loss: 0.390089  [ 6464/60000]\n",
      "loss: 0.256086  [12864/60000]\n",
      "loss: 0.295259  [19264/60000]\n",
      "loss: 0.287836  [25664/60000]\n",
      "loss: 0.396014  [32064/60000]\n",
      "loss: 0.194435  [38464/60000]\n",
      "loss: 0.501711  [44864/60000]\n",
      "loss: 0.281109  [51264/60000]\n",
      "loss: 0.318649  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.361795 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.167756  [   64/60000]\n",
      "loss: 0.388587  [ 6464/60000]\n",
      "loss: 0.240990  [12864/60000]\n",
      "loss: 0.291903  [19264/60000]\n",
      "loss: 0.268721  [25664/60000]\n",
      "loss: 0.389687  [32064/60000]\n",
      "loss: 0.192837  [38464/60000]\n",
      "loss: 0.485465  [44864/60000]\n",
      "loss: 0.270423  [51264/60000]\n",
      "loss: 0.296889  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.354869 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.163731  [   64/60000]\n",
      "loss: 0.387499  [ 6464/60000]\n",
      "loss: 0.228811  [12864/60000]\n",
      "loss: 0.289522  [19264/60000]\n",
      "loss: 0.254966  [25664/60000]\n",
      "loss: 0.384121  [32064/60000]\n",
      "loss: 0.192883  [38464/60000]\n",
      "loss: 0.470206  [44864/60000]\n",
      "loss: 0.262604  [51264/60000]\n",
      "loss: 0.282614  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.351642 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.161460  [   64/60000]\n",
      "loss: 0.385571  [ 6464/60000]\n",
      "loss: 0.219074  [12864/60000]\n",
      "loss: 0.287055  [19264/60000]\n",
      "loss: 0.244418  [25664/60000]\n",
      "loss: 0.377869  [32064/60000]\n",
      "loss: 0.193434  [38464/60000]\n",
      "loss: 0.459122  [44864/60000]\n",
      "loss: 0.255697  [51264/60000]\n",
      "loss: 0.272293  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.352760 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.159884  [   64/60000]\n",
      "loss: 0.382825  [ 6464/60000]\n",
      "loss: 0.211300  [12864/60000]\n",
      "loss: 0.284657  [19264/60000]\n",
      "loss: 0.237015  [25664/60000]\n",
      "loss: 0.371815  [32064/60000]\n",
      "loss: 0.194332  [38464/60000]\n",
      "loss: 0.449289  [44864/60000]\n",
      "loss: 0.250572  [51264/60000]\n",
      "loss: 0.264703  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.352307 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 8\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, predictor, loss_fn, optimizer)\n",
    "    test(test_dataloader, predictor, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26327398-178b-4c62-a735-99dac01e67e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "############## First step: I want to get the data first.  ################\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "training_images = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "############## Second step: I want to feem them into dataloaders ################\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader= DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader= DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "############## Third step: I want to define a neural network.  ################\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=2, stride=1, padding=0) #(64, 10, 27, 27)\n",
    "        self.bn = nn.BatchNorm2d(10)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) #(64, 10, 13, 13)\n",
    "        self.flatten = nn.Flatten() #(64, 13*13*10)\n",
    "        self.fc1 = nn.Linear(13*13*10, 10) # I expect input of shape (64, 1, 28 28)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.fc1(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf1fc53-b165-4600-b22e-f63803f8a1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "predictor = SimpleCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a508698f-e40b-4e31-8d23-f19529f33a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(predictor.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4075b5a8-679a-4035-a93c-b33babd041d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.575801  [   64/60000]\n",
      "loss: 0.518678  [ 6464/60000]\n",
      "loss: 0.313618  [12864/60000]\n",
      "loss: 0.491872  [19264/60000]\n",
      "loss: 0.417980  [25664/60000]\n",
      "loss: 0.469894  [32064/60000]\n",
      "loss: 0.312983  [38464/60000]\n",
      "loss: 0.561138  [44864/60000]\n",
      "loss: 0.407463  [51264/60000]\n",
      "loss: 0.482482  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.410526 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.231995  [   64/60000]\n",
      "loss: 0.401278  [ 6464/60000]\n",
      "loss: 0.274331  [12864/60000]\n",
      "loss: 0.349976  [19264/60000]\n",
      "loss: 0.336868  [25664/60000]\n",
      "loss: 0.442917  [32064/60000]\n",
      "loss: 0.253092  [38464/60000]\n",
      "loss: 0.519011  [44864/60000]\n",
      "loss: 0.311427  [51264/60000]\n",
      "loss: 0.428695  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.368295 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.195335  [   64/60000]\n",
      "loss: 0.377303  [ 6464/60000]\n",
      "loss: 0.271488  [12864/60000]\n",
      "loss: 0.313036  [19264/60000]\n",
      "loss: 0.310691  [25664/60000]\n",
      "loss: 0.425609  [32064/60000]\n",
      "loss: 0.230045  [38464/60000]\n",
      "loss: 0.502798  [44864/60000]\n",
      "loss: 0.290018  [51264/60000]\n",
      "loss: 0.380520  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.352734 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.176633  [   64/60000]\n",
      "loss: 0.368225  [ 6464/60000]\n",
      "loss: 0.262458  [12864/60000]\n",
      "loss: 0.300516  [19264/60000]\n",
      "loss: 0.293876  [25664/60000]\n",
      "loss: 0.406765  [32064/60000]\n",
      "loss: 0.220084  [38464/60000]\n",
      "loss: 0.489211  [44864/60000]\n",
      "loss: 0.281739  [51264/60000]\n",
      "loss: 0.342091  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.356991 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.169280  [   64/60000]\n",
      "loss: 0.363719  [ 6464/60000]\n",
      "loss: 0.250341  [12864/60000]\n",
      "loss: 0.294556  [19264/60000]\n",
      "loss: 0.279819  [25664/60000]\n",
      "loss: 0.393196  [32064/60000]\n",
      "loss: 0.214717  [38464/60000]\n",
      "loss: 0.475506  [44864/60000]\n",
      "loss: 0.276326  [51264/60000]\n",
      "loss: 0.315721  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.352968 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.166279  [   64/60000]\n",
      "loss: 0.361135  [ 6464/60000]\n",
      "loss: 0.238979  [12864/60000]\n",
      "loss: 0.290559  [19264/60000]\n",
      "loss: 0.267425  [25664/60000]\n",
      "loss: 0.384361  [32064/60000]\n",
      "loss: 0.211418  [38464/60000]\n",
      "loss: 0.463706  [44864/60000]\n",
      "loss: 0.271996  [51264/60000]\n",
      "loss: 0.297730  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.353377 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.164364  [   64/60000]\n",
      "loss: 0.358268  [ 6464/60000]\n",
      "loss: 0.229507  [12864/60000]\n",
      "loss: 0.287136  [19264/60000]\n",
      "loss: 0.256769  [25664/60000]\n",
      "loss: 0.377520  [32064/60000]\n",
      "loss: 0.208939  [38464/60000]\n",
      "loss: 0.453196  [44864/60000]\n",
      "loss: 0.268083  [51264/60000]\n",
      "loss: 0.285016  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.348489 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.163017  [   64/60000]\n",
      "loss: 0.354993  [ 6464/60000]\n",
      "loss: 0.221442  [12864/60000]\n",
      "loss: 0.283982  [19264/60000]\n",
      "loss: 0.247976  [25664/60000]\n",
      "loss: 0.371278  [32064/60000]\n",
      "loss: 0.207565  [38464/60000]\n",
      "loss: 0.444591  [44864/60000]\n",
      "loss: 0.264794  [51264/60000]\n",
      "loss: 0.275298  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.348994 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 8\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, predictor, loss_fn, optimizer)\n",
    "    test(test_dataloader, predictor, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
